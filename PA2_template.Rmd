```{r setoptions, echo=FALSE}
opts_chunk$set(fig.height=5)
```

## WEATHER SYSTEMS AND THEIR IMPACT ACROSS THE U.S.
***

## Section I: Synopsis

Synopsis: Immediately after the title, there should be a synopsis which describes and summarizes your analysis in at most 10 complete sentences.

## Section II: Data Processing

There should be a section titled Data Processing which describes (in words and code) how the data were loaded into R and processed for analysis. In particular, your analysis must start from the raw CSV file containing the data. You cannot do any preprocessing outside the document. If preprocessing is time-consuming you may consider using the cache = TRUE option for certain code chunks.

The basic goal of this assignment is to explore the NOAA Storm Database and answer some 
basic questions about severe weather events. You must use the database to answer the 
questions below and show the code for your entire analysis. Your analysis can consist of 
tables, figures, or other summaries. You may use any R package you want to support your analysis.

### Libraries

4 libraries were added for this assignment, which are the **ggplot2** graphics library, the **grid** library, the **gridExtra** library, and the **xtable** library:

```{r}
library(ggplot2)
library(grid)
library(gridExtra)
library(xtable)
```

All plots created in this assignment are **ggplot2** plots, consisting of histograms and time series plots.  The **gridExtra** library package allows for grid arrangement of multiple plots created with **ggplot2**, and **grid** is required for **gridExtra**. **xtable** is used to convert tables into HTML format.

### Downloading and Reading the Data

```{r downloading, warning=FALSE}
## ----------------------
## downloading code chunk
## ----------------------
## set the data directory for the analysis. As a single point of reference, 
## changes can be made here if required.
dataDir <- "./data/temp/repdata2/"

## set the name of the file to be used after download. As a single point of reference, 
## changes can be made here if required.
filename <- "StormData.csv"

## Preparing the directory locations:
## check if destination directories to be used already exist, relative to
## the working directory

if(!file.exists("data")) {dir.create("data")}
if(!file.exists(dataDir)) {dir.create(dataDir)}

## Check to see if the file already exists locally
if(!file.exists(paste(dataDir, filename, sep=""))) {
    
    ## file does not exist locally:
    ## note that BZ2 files are text files that R recognizes, so there is no need 
    ## for extraction. Download file renamed to StormData.csv, write to a text file
    ## today's date of download. If the CSV file does not exist, but the downloaded.txt 
    ## file already exists, the text file will be over written with a new file.
    
    fileUrl <- "https://d396qusza40orc.cloudfront.net/repdata%2Fdata%2FStormData.csv.bz2"
    download.file(fileUrl, destfile=paste(dataDir, filename, sep=""))
    writeLines(date(),paste(dataDir, "datedownloaded.txt", sep =""))
    datedownloaded <- paste(readLines(paste(dataDir, "datedownloaded.txt", sep ="")),
                            ", downloaded today", sep="")

} else {
    
    ## file exists locally:
    ## Save variable as local copy if file already exists.
    
    datedownloaded <- paste(readLines(paste(dataDir, "datedownloaded.txt", sep ="")),
                            ", localCopy", sep="")
}
```

Now that we have downloaded the raw data set, we can store it into a variable named ```weatherData```:

```{r reading, cache=TRUE}
## ------------------
## reading code chunk
## ------------------
weatherData <- read.csv(filename, sep=",")
```

Using inline R code, the following HTML table just states and records the ```filename``` and ```datedownloaded``` from the downloading code chunk above:

|            | File Used      | Downloaded                         |
| ----------:| --------------:| ----------------------------------:|
| **Record** | `r filename`   | `r datedownloaded`                 |

Recording this information will help in determining accuracy of the analysis if the data should change in the future. If there is an updated data set at the source site, then the date of the new data set can be compared against the ```datedownloaded``` of this analysis.  Adjustments can then be made to the analysis code to reflect the change, or margins of error can be calculated based on the differences.

Next we will use the ```weatherData``` data set to run some analysis. First, let's check the summary of the data set:

```{r cache=TRUE}
summary(weatherData)
```

We can take the varaibles from the above summary of the data set and cross reference the information about the variables in the National Weather Service PDF file [here](https://d396qusza40orc.cloudfront.net/repdata%2Fpeer2_doc%2Fpd01016005curr.pdf). Take a moment to peruse the PDF file to understand the variables listed in the raw data set.

Now that we understand the meaning behind the variables in the data set, we will move forward to answer some questions.

### Answering the Questions
  
#### Q1. Across the United States, which types of events (as indicated in the EVTYPE variable) are most harmful with respect to population health?
  
For this analysis, we will define "harm" as a combination of "fatalities" and "injuries" from the data set. Therefore, we will subset from ```weatherData``` only the variables that apply to this question.  From the summary of ```weatherData``` that we saw previously, the relevant variables that we will choose are:

* EVTYPE
* FATALITIES
* INJURIES

We saw from the summary of ```weatherData``` that the above listed variables do not have NA's in their observations, so we can now subset ```weatherData``` with the variables listed above, aggregate the event types and calculate the sum of the total harm done by each type, and then order the event type by the most damage done:

```{r harmOrdered}
## subset the event types and the harm they do, as popHarm
popHarm <- weatherData[, c("EVTYPE", "FATALITIES", "INJURIES")]

## calculate the sum of both fatalities and injuries for each event observation, as sunHarm
sumHarm <- popHarm$FATALITIES + popHarm$INJURIES
sumHarm <- cbind(popHarm, sumHarm)

## aggregate population health by sum into a new data set, aggregateHarm
aggregateHarm <- aggregate(. ~ EVTYPE, data = sumHarm, FUN = sum)

# Order the data set by the most damaging event type into a new data set, harmOrdered
harmOrdered <- aggregateHarm[order(-aggregateHarm$sumHarm),]
head(harmOrdered)
```

We can see that the most damaging event type is TORNADO, which we will plot in the Results section later using the tidy data set ```harmOrdered```.

#### Q2. Across the United States, which types of events have the greatest economic consequences?

  
**A2.** variables related to economy: propdmg, propdmgexp, cropdmg, cropdmgexp
 
 

## Section III: Results

There should be a section titled Results in which your results are presented.

### Conclusion  
  
Consider writing your report as if it were to be read by a government or municipal manager 
 who might be responsible for preparing for severe weather events and will need to prioritize 
 resources for different types of events. However, there is no need to make any specific 
 recommendations in your report.


 ## Document Layout

 The analysis document must have at least one figure containing a plot.

 Your analyis must have no more than three figures. Figures may have multiple plots in them 
 (i.e. panel plots), but there cannot be more than three figures total.

 You must show all your code for the work in your analysis document. This may make the document 
 a bit verbose, but that is okay. In general, you should ensure that echo = TRUE for every code 
 chunk (this is the default setting in knitr).

 Publishing Your Analysis

 For this assignment you will need to publish your analysis on RPubs.com. If you do not 
 already have an account, then you will have to create a new account. After you have completed 
 writing your analysis in RStudio, you can publish it to RPubs by doing the following:
  
   In RStudio, make sure your R Markdown document (.Rmd) document is loaded in the editor

   Click the Knit HTML button in the doc toolbar to preview your document.

   In the preview window, click the Publish button.

   Once your document is published to RPubs, you should get a unique URL to that document. 
   Make a note of this URL as you will need it to submit your assignment.

 NOTE: If you are having trouble connecting with RPubs due to proxy-related or other issues, 
 you can upload your final analysis document file as a PDF to Coursera instead.

 Submitting Your Assignment

 In order to submit this assignment, you must copy the RPubs URL for your completed data 
 analysis document in to the peer assessment question.
 
  