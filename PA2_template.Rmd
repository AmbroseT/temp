---
  title: "cssTest"
    output:
    html_document:
      css: custom.css
      toc: yes
---

```{r setoptions, echo=FALSE}
opts_chunk$set(fig.height=5)
```

## WEATHER SYSTEMS AND THEIR IMPACT ACROSS THE U.S.
***

## Section I: Synopsis

Synopsis: Immediately after the title, there should be a synopsis which describes and summarizes your analysis in at most 10 complete sentences.

## Section II: Data Processing

There should be a section titled Data Processing which describes (in words and code) how the data were loaded into R and processed for analysis. In particular, your analysis must start from the raw CSV file containing the data. You cannot do any preprocessing outside the document. If preprocessing is time-consuming you may consider using the cache = TRUE option for certain code chunks.

The basic goal of this assignment is to explore the NOAA Storm Database and answer some 
basic questions about severe weather events. You must use the database to answer the 
questions below and show the code for your entire analysis. Your analysis can consist of 
tables, figures, or other summaries. You may use any R package you want to support your analysis.

### Libraries

4 libraries were added for this assignment, which are the **ggplot2** graphics library, the **grid** library, the **gridExtra** library, and the **xtable** library:

```{r}
library(ggplot2)
library(grid)
library(gridExtra)
library(xtable)
```

All plots created in this assignment are **ggplot2** plots, consisting of histograms and time series plots.  The **gridExtra** library package allows for grid arrangement of multiple plots created with **ggplot2**, and **grid** is required for **gridExtra**. **xtable** is used to convert tables into HTML format.

### Downloading and Reading the Data

```{r downloading}
## ----------------------
## downloading code chunk
## ----------------------
## Preparing the directory locations:
## check if destination directories to be used already exist, relative to
## the working directory

if(!file.exists("data")) {dir.create("data")}
if(!file.exists("./data/temp/repdata2")) {dir.create("./data/temp/repdata2")}

## set the name of the file to be used after download
filename <- "StormData.csv"

## Check to see if the file already exists locally
if(!file.exists("StormData.csv")) {
    
    ## file does not exist locally:
    ## note that BZ2 files are just text files that R recognizes, so there is no need 
    ## for extraction. Download file renamed to StormData.csv, write to a text file
    ## today's date of download. If the CSV file does not exist, but the downloaded.txt 
    ## file already exists, the text file will be over written with a new file.
    
    fileUrl <- "https://d396qusza40orc.cloudfront.net/repdata%2Fdata%2FStormData.csv.bz2"
    download.file(fileUrl, destfile=filename)
    writeLines(Date(),"datedownloaded.txt")
    datedownloaded <- paste(readLines("datedownloaded.txt"),
                            ", downloaded today", sep="")

} else {
    
    ## file exists locally:
    ## Save variable as local copy if file already exists.
    
    datedownloaded <- paste(readLines("datedownloaded.txt"),
                            ", localCopy", sep="")
} 

```

Now that we have downloaded the raw data set, we can store it into a variable named ```weatherDdata``:

```{r reading, cache=TRUE}
## ------------------
## reading code chunk
## ------------------
weatherData <- read.csv(filename, sep=",")
```

Using inline R code, the following HTML table just states and records the ```filename``` and ```datedownloaded```, from the downloading code chunk above:

|            | File Used      | Downloaded          |
| ----------:| --------------:| -------------------:|
| **Record** | `r filename`   | `r datedownloaded`  |

Recording this information will help in determining accuracy of the analysis if the data should change in the future. If there is an updated date set, then the date of the new data set can be compared against the ```datedownloaded``` of this analysis.  Adjustments can then be made to the analysis code to reflect the change, or margins of error can be calculated based on the differences.

Next we will use the ```weatherData``` data set to run some analysis. First, let's check the summary of the data set:

```{r cache=TRUE}
summary(weatherData)
```

We can take the above summary of the variables in the data set and cross reference the information about the variables in the National Weather Service PDF file [here](https://d396qusza40orc.cloudfront.net/repdata%2Fpeer2_doc%2Fpd01016005curr.pdf).

Now that we understand the meaning behind the variables in the data set, we will move forward to answer some questions.

### Answering the Questions

Your data analysis must address the following questions:
  
#### Q1. Across the United States, which types of events (as indicated in the EVTYPE variable) are most harmful with respect to population health?

  
**A1.** data contains 'fatalities' and 'injuries' with regards to population health
  
  
  
#### Q2. Across the United States, which types of events have the greatest economic consequences?

  
**A2.** variables related to economy: propdmg, propdmgexp, cropdmg, cropdmgexp
 
 

## Section III: Results

There should be a section titled Results in which your results are presented.

### Conclusion  
  
Consider writing your report as if it were to be read by a government or municipal manager 
 who might be responsible for preparing for severe weather events and will need to prioritize 
 resources for different types of events. However, there is no need to make any specific 
 recommendations in your report.


 ## Document Layout

 The analysis document must have at least one figure containing a plot.

 Your analyis must have no more than three figures. Figures may have multiple plots in them 
 (i.e. panel plots), but there cannot be more than three figures total.

 You must show all your code for the work in your analysis document. This may make the document 
 a bit verbose, but that is okay. In general, you should ensure that echo = TRUE for every code 
 chunk (this is the default setting in knitr).

 Publishing Your Analysis

 For this assignment you will need to publish your analysis on RPubs.com. If you do not 
 already have an account, then you will have to create a new account. After you have completed 
 writing your analysis in RStudio, you can publish it to RPubs by doing the following:
  
   In RStudio, make sure your R Markdown document (.Rmd) document is loaded in the editor

   Click the Knit HTML button in the doc toolbar to preview your document.

   In the preview window, click the Publish button.

   Once your document is published to RPubs, you should get a unique URL to that document. 
   Make a note of this URL as you will need it to submit your assignment.

 NOTE: If you are having trouble connecting with RPubs due to proxy-related or other issues, 
 you can upload your final analysis document file as a PDF to Coursera instead.

 Submitting Your Assignment

 In order to submit this assignment, you must copy the RPubs URL for your completed data 
 analysis document in to the peer assessment question.
 
  