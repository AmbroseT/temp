```{r setoptions, echo=FALSE}
opts_chunk$set(fig.height=5)
```

## WEATHER SYSTEMS AND THEIR IMPACT ACROSS THE U.S.
***

## Section I: Synopsis

Synopsis: Immediately after the title, there should be a synopsis which describes and summarizes your analysis in at most 10 complete sentences.

## Section II: Data Processing

There should be a section titled Data Processing which describes (in words and code) how the data were loaded into R and processed for analysis. In particular, your analysis must start from the raw CSV file containing the data. You cannot do any preprocessing outside the document. If preprocessing is time-consuming you may consider using the cache = TRUE option for certain code chunks.

The basic goal of this assignment is to explore the NOAA Storm Database and answer some 
basic questions about severe weather events. You must use the database to answer the 
questions below and show the code for your entire analysis. Your analysis can consist of 
tables, figures, or other summaries. You may use any R package you want to support your analysis.

### Libraries

4 libraries were added for this assignment, which are the **ggplot2** graphics library, the **grid** library, the **gridExtra** library, and the **xtable** library:

```{r}
library(ggplot2)
library(grid)
library(gridExtra)
library(xtable)
```

All plots created in this assignment are **ggplot2** plots, consisting of histograms and time series plots.  The **gridExtra** library package allows for grid arrangement of multiple plots created with **ggplot2**, and **grid** is required for **gridExtra**. **xtable** is used to convert tables into HTML format.

### Downloading and Reading the Data

The following code details the directory creation, download of the raw data set, and reading in that raw data set. The directory structure, that this analysis was run, was separated to store some data into a directory off of the working directory for local reasons (i.e. separating assignments, projects, etc). The ```dataDir``` was created to add some flexibility here, for local changes or to accomodate other systems that are organized differently.

```{r downloading, warning=FALSE}
## ----------------------
## downloading code chunk
## ----------------------
## set the data directory for the analysis. As a single point of reference, 
## changes can be made here if required.
dataDir <- "./data/temp/repdata2/"

## set the name of the file to be used after download. As a single point of reference, 
## changes can be made here if required.
filename <- "StormData.csv"

## Preparing the directory locations:
## check if destination directories to be used already exist, relative to
## the working directory

if(!file.exists("data")) {dir.create("data")}
if(!file.exists(dataDir)) {dir.create(dataDir)}

## Check to see if the file already exists locally
if(!file.exists(paste(dataDir, filename, sep=""))) {
    
    ## file does not exist locally:
    ## note that BZ2 files are text files that R recognizes, so there is no need 
    ## for extraction. Download file renamed to StormData.csv, write to a text file
    ## today's date of download. If the CSV file does not exist, but the downloaded.txt 
    ## file already exists, the text file will be over written with a new file.
    
    fileUrl <- "https://d396qusza40orc.cloudfront.net/repdata%2Fdata%2FStormData.csv.bz2"
    download.file(fileUrl, destfile=paste(dataDir, filename, sep=""))
    writeLines(date(),paste(dataDir, "datedownloaded.txt", sep =""))
    datedownloaded <- paste(readLines(paste(dataDir, "datedownloaded.txt", sep ="")),
                            ", downloaded today", sep="")

} else {
    
    ## file exists locally:
    ## Save variable as local copy if file already exists.
    
    datedownloaded <- paste(readLines(paste(dataDir, "datedownloaded.txt", sep ="")),
                            ", localCopy", sep="")
}
```

Now that we have downloaded the raw data set, we can store it into a data frame named ```weatherData```:

```{r reading, cache=TRUE}
## ------------------
## reading code chunk
## ------------------
weatherData <- read.csv(filename, sep=",")
```

Using inline R code, the following HTML table just states and records ```filename``` and ```datedownloaded``` from the downloading code chunk above:

|            | File Used      | Downloaded                         |
| ----------:| --------------:| ----------------------------------:|
| **Record** | `r filename`   | `r datedownloaded`                 |

Recording this information will help in determining accuracy of the analysis if the data source should change in the future. If there is an updated data set at the source site, then the date of the new data set can be compared against ```datedownloaded``` of this analysis.  Adjustments can then be made to the analysis code to reflect the change, or margins of error can be calculated based on the differences.

Next we will use the ```weatherData``` data set and run some analysis against it. First, let's check the summary of the data set:

```{r weatherSummary, cache=TRUE}
summary(weatherData)
```

We can take the variables from the above summary of the data set and cross reference the information about the data in the National Weather Service PDF file [here](https://d396qusza40orc.cloudfront.net/repdata%2Fpeer2_doc%2Fpd01016005curr.pdf). Take a moment to peruse the PDF file to understand the variables listed in the raw data set.

Now that we understand the meaning behind the variables in the data set, we will move forward to answer some questions.

### Answering the Questions
  
#### Q1. Across the United States, which types of events (as indicated in the EVTYPE variable) are most harmful with respect to population health?
  
For this analysis, we will define "harm" as a combination of both "fatalities" and "injuries" from the data set. Therefore, we will subset from ```weatherData``` only the variables that apply to this question.  From the summary of ```weatherData``` that we saw previously, the relevant variables that we have chosen are:

* EVTYPE
* FATALITIES
* INJURIES

We saw from the summary of ```weatherData``` that the above listed variables do not have NA's in their observations, so we can now subset ```weatherData``` with the variables listed above, aggregate the event types and calculate the sum of the total harm done by each type, and then order the event type by the most damage done:

```{r harmOrdered, cache=TRUE}
## subset the event types and the harm they do, as popHarm
popHarm <- weatherData[, c("EVTYPE", "FATALITIES", "INJURIES")]

## calculate the sum of both fatalities and injuries for each event observation, as sunHarm
sumHarm <- popHarm$FATALITIES + popHarm$INJURIES
sumHarm <- cbind(popHarm, sumHarm)

## aggregate population harm by sum into a new data set, aggregateHarm
aggregateHarm <- aggregate(. ~ EVTYPE, data = sumHarm, FUN = sum)

# Order the data set by the most damaging event type into a new data set, harmOrdered
harmOrdered <- aggregateHarm[order(-aggregateHarm$sumHarm),]
head(harmOrdered)
```

We can see that the most damaging event type is TORNADO, which we will plot in the Results section later using the tidy data set ```harmOrdered```.

#### Q2. Across the United States, which types of events have the greatest economic consequences?

For this analysis, we will define "economic consequences" as a measurement of damages to property and crops in monetary value of U.S. dollars. According to page 12, section 2.7 of the National Weather Service PDF [file](https://d396qusza40orc.cloudfront.net/repdata%2Fpeer2_doc%2Fpd01016005curr.pdf), monetary values are estimates rounded to three significant digits, followed by an alphabetical character signifying the numerical magnitude. The three alphabetical characters and their designation are as follows:

- **K** - for thousands
- **M** - for millions
- **B** - for billions

This will be represented in R code as:
```{r alphaNums}
## The three alphabetical characters and their designation
k <- 1e3
m <- 1e6
b <- 1e9
```

All other designations will be ignored, since they cover other scenarios of ambiguity or exclusion.

From the raw data set ```weatherData```, the numerical estimates are stored in the following variables:

- PROPDMG
- CROPDMG

And as follows, the alphabetical characters are stored in the following variables variables (corresponding to ```PROPDMG``` and ```CROPDMG```):

- PROPDMGEXP
- CROPDMGEXP

When each respective variables are paired, the combination represents the monetary value in USD. Example, using inline R code:

| PROPDMG | PROPDMGEXP | CROPDMG | CROPDMGEXP | VALUE IN USD             |
| -------:| ----------:| -------:| ----------:| ------------------------:|
| 1.55    | m          |         |            | `r as.integer(1.55 * m)` |
|         |            | 1.36    | K          | `r as.integer(1.36 * k)` |

We will use the above model to calculate full monetary values for property damage and crop damage, in new variables respectively, and ```cbind()``` them to a new data set, named ```kmb```.

It is important to note that we will need to consider case sensitivity for ```PROPDMGEXP``` and ```CROPDMGEXP``` since both upper and lower cases have been recorded:

```{r characters, cache=TRUE}
## list the alphabetical characters used for property damage
unique(weatherData$PROPDMGEXP)

## list the alphabetical characters used for crop damage
unique(weatherData$CROPDMGEXP)
```

The 4 ```weatherData``` variables and the variable ```EVTYPE``` will be the relevant variables to subset from the raw data set ```weatherData```. Reviewing the summary of ```weatherDatda``` shows that the variables mentioned do not have NA values in the observations. a new data set ```kmb``` will be created, then aggregated by event type, and the sum total economic consequences for each event type will be calculated after the ```cbind()``` process. 

```{r kmb}
## sprintf("$%14.2f",b)

## subset weatherData for the relevant variables relevant to economic consequences
ecoDmg <- weatherData[, c("EVTYPE", "PROPDMG", "PROPDMGEXP", "CROPDMG", "CROPDMGEXP")]

## convert from factor to character
ecoDmg$PROPDMGEXP <- as.character(ecoDmg$PROPDMGEXP)
ecoDmg$CROPDMGEXP <- as.character(ecoDmg$CROPDMGEXP)

## divide into 2 data sets, one for property (ecoDmg.prop), and one for crops (ecoDmg.crop)
ecoDmg.prop <- ecoDmg[, c("EVTYPE","PROPDMG","PROPDMGEXP")]
ecoDmg.crop <- ecoDmg[, c("EVTYPE","CROPDMG","CROPDMGEXP")]

## testing
head(ecoDmg.prop)
head(ecoDmg.crop)

kmb.crop <- ecoDmg.crop[grep("[kK]|[mM]|[bB]", ecoDmg.crop$CROPDMGEXP), ]
kmb.prop <- ecoDmg.prop[grep("[kK]|[mM]|[bB]", ecoDmg.prop$PROPDMGEXP), ]

unique(kmb.crop$CROPDMGEXP)
unique(kmb.prop$PROPDMGEXP)

head(kmb.crop)
head(kmb.prop)
```

```{r}
## find and replace 'k', 'm', and 'b' with equivalent value for property damage
kmb.prop$PROPDMGEXP <- sapply(kmb.prop$PROPDMGEXP, function(i) ifelse(i=="k" | i=="K", k, i))
kmb.prop$PROPDMGEXP <- sapply(kmb.prop$PROPDMGEXP, function(i) ifelse(i=="m" | i=="M", m, i))
kmb.prop$PROPDMGEXP <- sapply(kmb.prop$PROPDMGEXP, function(i) ifelse(i=="b" | i=="B", b, i))

## testing
## unique(kmb.prop$PROPDMGEXP)
## head(kmb.prop)
## str(kmb.prop)

## find and replace 'k', 'm', and 'b' with equivalent value for crop damage
kmb.crop$CROPDMGEXP <- sapply(kmb.crop$CROPDMGEXP, function(i) ifelse(i=="k" | i=="K", k, i))
kmb.crop$CROPDMGEXP <- sapply(kmb.crop$CROPDMGEXP, function(i) ifelse(i=="m" | i=="M", m, i))
kmb.crop$CROPDMGEXP <- sapply(kmb.crop$CROPDMGEXP, function(i) ifelse(i=="b" | i=="B", b, i))

## testing
## unique(kmb.crop$CROPDMGEXP)
## head(kmb.crop)
## str(kmb.crop)
```

```{r}
## Convert to numeric
kmb.prop$PROPDMGEXP <- as.numeric(kmb.prop$PROPDMGEXP)
kmb.crop$CROPDMGEXP <- as.numeric(kmb.crop$CROPDMGEXP)
```

```{r}
## Multiply and cbind
kmb.prop <- cbind(kmb.prop, propVal = kmb.prop$PROPDMG * kmb.prop$PROPDMGEXP)
kmb.crop <- cbind(kmb.crop, cropVal = kmb.crop$CROPDMG * kmb.crop$CROPDMGEXP)

## testing, are there NA, other unwanted values
summary(kmb.prop)
summary(kmb.crop)

unique(kmb.prop$PROPDMGEXP)
unique(kmb.crop$CROPDMGEXP)

head(kmb.prop)
head(kmb.crop)
str(kmb.prop)
str(kmb.crop)

## convert from factor to character
kmb.prop$EVTYPE <- as.character(kmb.prop$EVTYPE)
kmb.crop$EVTYPE <- as.character(kmb.crop$EVTYPE)

## subset just the necessary variables, 'evtype' and 'propVal'
kmb.prop2 <- kmb.prop[,c("EVTYPE","propVal")]

## subset just the necessary variables, 'evtype' and 'cropVal'
kmb.crop2 <- kmb.crop[,c("EVTYPE","cropVal")]

## aggregate as in Q1
aggregateProp <- aggregate(. ~ EVTYPE, data = kmb.prop2, FUN = sum)
aggregateCrop <- aggregate(. ~ EVTYPE, data = kmb.crop2, FUN = sum)

## convert propVal to represent billions
aggregateProp$propVal <- aggregateProp$propVal / 1e9 
aggregateCrop$cropVal <- aggregateCrop$cropVal / 1e9 

## order property data by highest damage value
propTotal <- aggregateProp[order(-aggregateProp$propVal),]

## order crop data by highest damage value
cropTotal <- aggregateCrop[order(-aggregateCrop$cropVal),]

## merge crop and property data
ecoMerged <- merge(propTotal, cropTotal)

## create a new variable that calculates the sum of crop and property damage
## by evtype
ecoTotal <- cbind(ecoMerged, Total = ecoMerged$propVal + ecoMerged$cropVal)

## order total damage value per type by highest damage value
ecoTotal <- ecoTotal[order(-ecoTotal$Total),]
```

```{r}
## take a look at the highest monetary loss in billions USD under each category
head(propTotal)
head(cropTotal)
head(ecoTotal)
```

From the new tidy data sets we created, ```cropTotal```, ```propTotal```, and ```ecoTotal```, we can see different losses under each category, sorted by the highest amount lost in billions USD.  We will use this information to create a plot in the Results section later.

## Section III: Results

We will now revisit the questions asked in Section II, and plot the results for the answers.

#### Q1. Across the United States, which types of events (as indicated in the EVTYPE variable) are most harmful with respect to population health?

#### Q2. Across the United States, which types of events have the greatest economic consequences?

### Conclusion  
  
Consider writing your report as if it were to be read by a government or municipal manager 
 who might be responsible for preparing for severe weather events and will need to prioritize 
 resources for different types of events. However, there is no need to make any specific 
 recommendations in your report.


 ## Document Layout

 The analysis document must have at least one figure containing a plot.

 Your analyis must have no more than three figures. Figures may have multiple plots in them 
 (i.e. panel plots), but there cannot be more than three figures total.

 You must show all your code for the work in your analysis document. This may make the document 
 a bit verbose, but that is okay. In general, you should ensure that echo = TRUE for every code 
 chunk (this is the default setting in knitr).

 ## Publishing Your Analysis

 For this assignment you will need to publish your analysis on RPubs.com. If you do not 
 already have an account, then you will have to create a new account. After you have completed 
 writing your analysis in RStudio, you can publish it to RPubs by doing the following:
  
   In RStudio, make sure your R Markdown document (.Rmd) document is loaded in the editor

   Click the Knit HTML button in the doc toolbar to preview your document.

   In the preview window, click the Publish button.

   Once your document is published to RPubs, you should get a unique URL to that document. 
   Make a note of this URL as you will need it to submit your assignment.

 NOTE: If you are having trouble connecting with RPubs due to proxy-related or other issues, 
 you can upload your final analysis document file as a PDF to Coursera instead.

 Submitting Your Assignment

 In order to submit this assignment, you must copy the RPubs URL for your completed data 
 analysis document in to the peer assessment question.
 
  